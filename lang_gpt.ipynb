{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "ndZzrAcRTBBX",
        "outputId": "5c83d070-1f29-4515-f9d9-eb3c8f58be49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (0.3.21)\n",
            "Requirement already satisfied: langchain_openai in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (0.3.11)\n",
            "Requirement already satisfied: openai in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (1.69.0)\n",
            "Requirement already satisfied: langchain_google_genai in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (2.1.2)\n",
            "Collecting dotenv\n",
            "  Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from langchain) (0.3.49)\n",
            "Requirement already satisfied: PyYAML>=5.3 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from langchain) (2.11.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from langchain) (0.3.19)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from langchain) (0.3.7)\n",
            "Requirement already satisfied: requests<3,>=2 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (4.13.0)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (24.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: certifi in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: anyio in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: idna in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: greenlet>=1 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: tqdm>4 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.2.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: colorama in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.16 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from langchain_google_genai) (0.6.17)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from langchain_google_genai) (1.2.0)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (2.24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (5.29.4)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (1.26.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (2.38.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (1.69.2)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (1.71.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in d:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (0.6.1)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, dotenv\n",
            "Successfully installed dotenv-0.9.9 python-dotenv-1.1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.1.3; however, version 25.0.1 is available.\n",
            "You should consider upgrading via the 'd:\\code_aveangers\\projects-2024\\lang_gpt\\lang_gpt\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain langchain_openai openai langchain_google_genai dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "A1C3AYn2SCgY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sqlite3\n",
        "from datetime import datetime\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import LLMChain, SequentialChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, llms\n",
        "\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JgLzhXtxqz8"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAzQ0HPOfbWQcJY5nKHJJgfO2P-pNmlaok\"\n",
        "MODEL = \"GEMINI\" # or \"OPENAI\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYvYS2TLWIrM",
        "outputId": "68d26fb8-a61e-483b-8027-061a1f365bca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziOt2TBTxzBt"
      },
      "outputs": [],
      "source": [
        "def init_db():\n",
        "    conn = sqlite3.connect('language_learning.db')\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS users (\n",
        "        user_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        native_language TEXT,\n",
        "        learning_language TEXT,\n",
        "        proficiency_level TEXT,\n",
        "        created_at TIMESTAMP\n",
        "    )\n",
        "    ''')\n",
        "\n",
        "    cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS sessions (\n",
        "        session_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        user_id INTEGER,\n",
        "        scene TEXT,\n",
        "        start_time TIMESTAMP,\n",
        "        end_time TIMESTAMP,\n",
        "        FOREIGN KEY (user_id) REFERENCES users (user_id)\n",
        "    )\n",
        "    ''')\n",
        "\n",
        "    cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS mistakes (\n",
        "        mistake_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        session_id INTEGER,\n",
        "        user_message TEXT,\n",
        "        mistake_text TEXT,\n",
        "        correction TEXT,\n",
        "        mistake_type TEXT,\n",
        "        explanation TEXT,\n",
        "        created_at TIMESTAMP,\n",
        "        FOREIGN KEY (session_id) REFERENCES sessions (session_id)\n",
        "    )\n",
        "    ''')\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def create_user(native_language, learning_language, proficiency_level):\n",
        "    conn = sqlite3.connect('language_learning.db')\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    cursor.execute('''\n",
        "    INSERT INTO users (native_language, learning_language, proficiency_level, created_at)\n",
        "    VALUES (?, ?, ?, ?)\n",
        "    ''', (native_language, learning_language, proficiency_level, datetime.now()))\n",
        "\n",
        "    user_id = cursor.lastrowid\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "    return user_id\n",
        "n\n",
        "def start_session(user_id, scene):\n",
        "    conn = sqlite3.connect('language_learning.db')\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    cursor.execute('''\n",
        "    INSERT INTO sessions (user_id, scene, start_time)\n",
        "    VALUES (?, ?, ?)\n",
        "    ''', (user_id, scene, datetime.now()))\n",
        "\n",
        "    session_id = cursor.lastrowid\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "    return session_id\n",
        "\n",
        "def end_session(session_id):\n",
        "    conn = sqlite3.connect('language_learning.db')\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    cursor.execute('''\n",
        "    UPDATE sessions SET end_time = ? WHERE session_id = ?\n",
        "    ''', (datetime.now(), session_id))\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def record_mistake(session_id, user_message, mistake_text, correction, mistake_type, explanation):\n",
        "    conn = sqlite3.connect('language_learning.db')\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    cursor.execute('''\n",
        "    INSERT INTO mistakes (session_id, user_message, mistake_text, correction, mistake_type, explanation, created_at)\n",
        "    VALUES (?, ?, ?, ?, ?, ?, ?)\n",
        "    ''', (session_id, user_message, mistake_text, correction, mistake_type, explanation, datetime.now()))\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def get_session_mistakes(session_id):\n",
        "    conn = sqlite3.connect('language_learning.db')\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    cursor.execute('''\n",
        "    SELECT mistake_text, correction, mistake_type, explanation\n",
        "    FROM mistakes\n",
        "    WHERE session_id = ?\n",
        "    ''', (session_id,))\n",
        "\n",
        "    mistakes = cursor.fetchall()\n",
        "    conn.close()\n",
        "\n",
        "    return mistakes\n",
        "\n",
        "def get_user_info(user_id):\n",
        "    conn = sqlite3.connect('language_learning.db')\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    cursor.execute('''\n",
        "    SELECT native_language, learning_language, proficiency_level\n",
        "    FROM users\n",
        "    WHERE user_id = ?\n",
        "    ''', (user_id,))\n",
        "\n",
        "    user_info = cursor.fetchone()\n",
        "    conn.close()\n",
        "\n",
        "    return user_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVSu4lhUx4N5"
      },
      "outputs": [],
      "source": [
        "SCENES = {\n",
        "    \"restaurant\": \"You are at a restaurant and need to order food.\",\n",
        "    \"hotel\": \"You are checking into a hotel and discussing your reservation.\",\n",
        "    \"shopping\": \"You are shopping for clothes and asking for help.\",\n",
        "    \"doctor\": \"You are at a doctor's appointment describing symptoms.\",\n",
        "    \"transport\": \"You are asking for directions and transportation information.\",\n",
        "    \"none\": \"Free conversation with no specific scene - talk about any topic.\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_UFejFm1E73"
      },
      "outputs": [],
      "source": [
        "def get_language_model():\n",
        "    if MODEL == \"GEMINI\":\n",
        "        return ChatGoogleGenerativeAI(\n",
        "            model=\"gemini-1.5-pro\",\n",
        "            temperature=0.5,\n",
        "            api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
        "        )\n",
        "    else:\n",
        "        return ChatOpenAI(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            temperature=0.7,\n",
        "            api_key=os.getenv(\"OPENAI_API_KEY\")\n",
        "        )\n",
        "\n",
        "\n",
        "def init_conversation_agent(native_language, learning_language, proficiency_level, scene):\n",
        "    memory = ConversationBufferMemory(memory_key=\"chat_history\",input_key=\"input\", return_messages=True)\n",
        "\n",
        "    conversation_prompt = PromptTemplate(\n",
        "        input_variables=[\"native_language\", \"learning_language\", \"proficiency_level\", \"scene\", \"chat_history\", \"input\"],\n",
        "        template=\"\"\"\n",
        "        You are a language learning assistant helping someone learn {learning_language}.\n",
        "        The student's native language is {native_language} and their proficiency level in {learning_language} is {proficiency_level}.\n",
        "\n",
        "        Current scene: {scene}\n",
        "\n",
        "        Previous conversation:\n",
        "        {chat_history}\n",
        "\n",
        "        Rules:\n",
        "        1. Primarily use {learning_language} in your responses, but adjust complexity based on the proficiency level\n",
        "        2. For beginners, use simple phrases and include translations to {native_language} in parentheses\n",
        "        3. For intermediate learners, use more complex sentences and only translate difficult phrases\n",
        "        4. For advanced learners, use natural speech with idioms and colloquialisms\n",
        "        5. Stay in character for the scene\n",
        "        6. If the user makes a language mistake, gently correct it and explain the correction\n",
        "        7. Keep responses concise and focused on the conversation\n",
        "\n",
        "        User's message: {input}\n",
        "\n",
        "        Your response in {learning_language} (with appropriate help based on their level):\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    conversation_chain = LLMChain(\n",
        "        llm=get_language_model(),\n",
        "        prompt=conversation_prompt,\n",
        "        memory=memory,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    return conversation_chain\n",
        "\n",
        "def init_error_detection_agent(native_language, learning_language, proficiency_level):\n",
        "    error_prompt = PromptTemplate(\n",
        "        input_variables=[\"native_language\", \"learning_language\", \"proficiency_level\", \"user_message\"],\n",
        "        template=\"\"\"\n",
        "        Analyze the following message from a {learning_language} language learner whose native language is {native_language} and proficiency level is {proficiency_level}.\n",
        "\n",
        "        User's message: {user_message}\n",
        "\n",
        "        Identify any language mistakes in the JSON format below. If there are no mistakes, return an empty array.\n",
        "\n",
        "        ```json\n",
        "        [\n",
        "            {{\n",
        "                \"mistake_text\": \"the incorrect text\",\n",
        "                \"correction\": \"the corrected text\",\n",
        "                \"mistake_type\": \"grammar|vocabulary|spelling|pronunciation|structure\",\n",
        "                \"explanation\": \"Brief explanation of the error and why the correction is better\"\n",
        "            }}\n",
        "        ]\n",
        "        ```\n",
        "\n",
        "        Only return the JSON, nothing else.\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    error_chain = LLMChain(\n",
        "        llm=get_language_model(),\n",
        "        prompt=error_prompt,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    return error_chain\n",
        "\n",
        "def init_review_agent(native_language, learning_language):\n",
        "    review_prompt = PromptTemplate(\n",
        "        input_variables=[\"native_language\", \"learning_language\", \"mistakes\"],\n",
        "        template=\"\"\"\n",
        "        Based on the following mistakes made during a {learning_language} learning session by a {native_language} speaker, provide:\n",
        "\n",
        "        1. A summary of the key areas needing improvement\n",
        "        2. Patterns in the mistakes\n",
        "        3. 3-5 specific practice recommendations\n",
        "        4. Encouragement on what was done well\n",
        "\n",
        "        Mistakes:\n",
        "        {mistakes}\n",
        "\n",
        "        Provide your analysis in both {learning_language} and {native_language}.\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    review_chain = LLMChain(\n",
        "        llm=get_language_model(),\n",
        "        prompt=review_prompt,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    return review_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vk9OiQhK1GoB"
      },
      "outputs": [],
      "source": [
        "class LanguageLearningChatbot:\n",
        "    def __init__(self):\n",
        "        init_db()\n",
        "        self.user_id = None\n",
        "        self.session_id = None\n",
        "        self.conversation_agent = None\n",
        "        self.error_detection_agent = None\n",
        "        self.review_agent = None\n",
        "        self.user_info = None\n",
        "\n",
        "    def start_onboarding(self):\n",
        "        print(\"Welcome to the Language Learning Chatbot!\")\n",
        "        print(\"Let's set up your profile.\")\n",
        "\n",
        "        native_language = input(\"What is your native language? \")\n",
        "        learning_language = input(\"What language would you like to learn? \")\n",
        "\n",
        "        print(\"\\nWhat is your current level in {}?\".format(learning_language))\n",
        "        print(\"1. Beginner\")\n",
        "        print(\"2. Intermediate\")\n",
        "        print(\"3. Advanced\")\n",
        "        level_choice = input(\"Enter the number (1-3): \")\n",
        "\n",
        "        level_map = {\n",
        "            \"1\": \"beginner\",\n",
        "            \"2\": \"intermediate\",\n",
        "            \"3\": \"advanced\"\n",
        "        }\n",
        "        proficiency_level = level_map.get(level_choice, \"beginner\")\n",
        "\n",
        "        self.user_id = create_user(native_language, learning_language, proficiency_level)\n",
        "        self.user_info = (native_language, learning_language, proficiency_level)\n",
        "\n",
        "        self.error_detection_agent = init_error_detection_agent(\n",
        "            native_language, learning_language, proficiency_level\n",
        "        )\n",
        "\n",
        "        print(\"\\nGreat! Profile created. Now let's choose a conversation scene.\")\n",
        "        self.select_scene()\n",
        "\n",
        "    def select_scene(self):\n",
        "        print(\"\\nAvailable conversation scenes:\")\n",
        "        for i, (scene_key, scene_desc) in enumerate(SCENES.items(), 1):\n",
        "            print(f\"{i}. {scene_key.title()}: {scene_desc}\")\n",
        "\n",
        "        scene_choice = input(\"\\nEnter the number of your chosen scene (1-5): \")\n",
        "        try:\n",
        "            scene_index = int(scene_choice) - 1\n",
        "            scene_key = list(SCENES.keys())[scene_index]\n",
        "            scene_desc = SCENES[scene_key]\n",
        "        except (ValueError, IndexError):\n",
        "            print(\"Invalid choice. Selecting 'restaurant' as default.\")\n",
        "            scene_key = \"restaurant\"\n",
        "            scene_desc = SCENES[scene_key]\n",
        "\n",
        "        self.session_id = start_session(self.user_id, scene_key)\n",
        "\n",
        "        native_language, learning_language, proficiency_level = self.user_info\n",
        "        self.conversation_agent = init_conversation_agent(\n",
        "            native_language, learning_language, proficiency_level, scene_desc\n",
        "        )\n",
        "\n",
        "        print(f\"\\nScene set: {scene_key.title()} - {scene_desc}\")\n",
        "        print(\"Let's start the conversation. Type 'exit' at any time to end the session.\")\n",
        "\n",
        "        initial_response = self.conversation_agent.run(\n",
        "            native_language=native_language,\n",
        "            learning_language=learning_language,\n",
        "            proficiency_level=proficiency_level,\n",
        "            scene=scene_desc,\n",
        "            input=\"Hello! Start the conversation in this scene.\"\n",
        "        )\n",
        "\n",
        "        print(f\"\\nBot: {initial_response}\")\n",
        "        self.chat_loop()\n",
        "\n",
        "    def chat_loop(self):\n",
        "        while True:\n",
        "            user_message = input(\"\\nYou: \")\n",
        "\n",
        "            if user_message.lower() == 'exit':\n",
        "                self.end_session()\n",
        "                break\n",
        "\n",
        "            native_language, learning_language, proficiency_level = self.user_info\n",
        "            error_analysis = self.error_detection_agent.run(\n",
        "                native_language=native_language,\n",
        "                learning_language=learning_language,\n",
        "                proficiency_level=proficiency_level,\n",
        "                user_message=user_message\n",
        "            )\n",
        "\n",
        "            try:\n",
        "                import json\n",
        "                errors = json.loads(error_analysis)\n",
        "                for error in errors:\n",
        "                    record_mistake(\n",
        "                        self.session_id,\n",
        "                        user_message,\n",
        "                        error[\"mistake_text\"],\n",
        "                        error[\"correction\"],\n",
        "                        error[\"mistake_type\"],\n",
        "                        error[\"explanation\"]\n",
        "                    )\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing mistakes: {e}\")\n",
        "\n",
        "            bot_response = self.conversation_agent.run(\n",
        "                native_language=native_language,\n",
        "                learning_language=learning_language,\n",
        "                proficiency_level=proficiency_level,\n",
        "                scene=SCENES[self.get_current_scene()],\n",
        "                input=user_message\n",
        "            )\n",
        "\n",
        "            print(f\"\\nBot: {bot_response}\")\n",
        "\n",
        "    def get_current_scene(self):\n",
        "        conn = sqlite3.connect('language_learning.db')\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        cursor.execute('''\n",
        "        SELECT scene FROM sessions WHERE session_id = ?\n",
        "        ''', (self.session_id,))\n",
        "\n",
        "        scene = cursor.fetchone()[0]\n",
        "        conn.close()\n",
        "\n",
        "        return scene\n",
        "\n",
        "    def end_session(self):\n",
        "        end_session(self.session_id)\n",
        "\n",
        "        mistakes = get_session_mistakes(self.session_id)\n",
        "\n",
        "        if not mistakes:\n",
        "            print(\"\\nSession complete! You made no mistakes in this session. Great job!\")\n",
        "            return\n",
        "\n",
        "        mistakes_formatted = \"\\n\".join([\n",
        "            f\"- Mistake: '{mistake[0]}', Correction: '{mistake[1]}', Type: {mistake[2]}, Explanation: {mistake[3]}\"\n",
        "            for mistake in mistakes\n",
        "        ])\n",
        "\n",
        "        if not self.review_agent:\n",
        "            native_language, learning_language, _ = self.user_info\n",
        "            self.review_agent = init_review_agent(native_language, learning_language)\n",
        "\n",
        "        native_language, learning_language, _ = self.user_info\n",
        "        review = self.review_agent.run(\n",
        "            native_language=native_language,\n",
        "            learning_language=learning_language,\n",
        "            mistakes=mistakes_formatted\n",
        "        )\n",
        "\n",
        "        print(\"\\n----- SESSION REVIEW -----\")\n",
        "        print(review)\n",
        "        print(\"-------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs0YBjZdWmSi",
        "outputId": "e0c241b0-a457-4dc8-c4bb-379c7afb4620"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the Language Learning Chatbot!\n",
            "Let's set up your profile.\n",
            "What is your native language? Odia\n",
            "What language would you like to learn? English\n",
            "\n",
            "What is your current level in English?\n",
            "1. Beginner\n",
            "2. Intermediate\n",
            "3. Advanced\n",
            "Enter the number (1-3): 1\n",
            "\n",
            "Great! Profile created. Now let's choose a conversation scene.\n",
            "\n",
            "Available conversation scenes:\n",
            "1. Restaurant: You are at a restaurant and need to order food.\n",
            "2. Hotel: You are checking into a hotel and discussing your reservation.\n",
            "3. Shopping: You are shopping for clothes and asking for help.\n",
            "4. Doctor: You are at a doctor's appointment describing symptoms.\n",
            "5. Transport: You are asking for directions and transportation information.\n",
            "6. None: Free conversation with no specific scene - talk about any topic.\n",
            "\n",
            "Enter the number of your chosen scene (1-5): 5\n",
            "\n",
            "Scene set: Transport - You are asking for directions and transportation information.\n",
            "Let's start the conversation. Type 'exit' at any time to end the session.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "        You are a language learning assistant helping someone learn English. \n",
            "        The student's native language is Odia and their proficiency level in English is beginner.\n",
            "        \n",
            "        Current scene: You are asking for directions and transportation information.\n",
            "        \n",
            "        Previous conversation:\n",
            "        []\n",
            "        \n",
            "        Rules:\n",
            "        1. Primarily use English in your responses, but adjust complexity based on the proficiency level\n",
            "        2. For beginners, use simple phrases and include translations to Odia in parentheses\n",
            "        3. For intermediate learners, use more complex sentences and only translate difficult phrases\n",
            "        4. For advanced learners, use natural speech with idioms and colloquialisms\n",
            "        5. Stay in character for the scene\n",
            "        6. If the user makes a language mistake, gently correct it and explain the correction\n",
            "        7. Keep responses concise and focused on the conversation\n",
            "        \n",
            "        User's message: Hello! Start the conversation in this scene.\n",
            "        \n",
            "        Your response in English (with appropriate help based on their level):\n",
            "        \u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Bot: Hello!  Excuse me (କ୍ଷମା କରିବେ), where is the train station? (ଟ୍ରେନ୍ ଷ୍ଟେସନ୍ କେଉଁଠି?)\n",
            "\n",
            "You: Soro\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "        Analyze the following message from a English language learner whose native language is Odia and proficiency level is beginner.\n",
            "        \n",
            "        User's message: Soro\n",
            "        \n",
            "        Identify any language mistakes in the JSON format below. If there are no mistakes, return an empty array.\n",
            "        \n",
            "        ```json\n",
            "        [\n",
            "            {\n",
            "                \"mistake_text\": \"the incorrect text\",\n",
            "                \"correction\": \"the corrected text\",\n",
            "                \"mistake_type\": \"grammar|vocabulary|spelling|pronunciation|structure\",\n",
            "                \"explanation\": \"Brief explanation of the error and why the correction is better\"\n",
            "            }\n",
            "        ]\n",
            "        ```\n",
            "        \n",
            "        Only return the JSON, nothing else.\n",
            "        \u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Error processing mistakes: Expecting value: line 1 column 1 (char 0)\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "        You are a language learning assistant helping someone learn English. \n",
            "        The student's native language is Odia and their proficiency level in English is beginner.\n",
            "        \n",
            "        Current scene: You are asking for directions and transportation information.\n",
            "        \n",
            "        Previous conversation:\n",
            "        [HumanMessage(content='Hello! Start the conversation in this scene.', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello!  Excuse me (କ୍ଷମା କରିବେ), where is the train station? (ଟ୍ରେନ୍ ଷ୍ଟେସନ୍ କେଉଁଠି?)', additional_kwargs={}, response_metadata={})]\n",
            "        \n",
            "        Rules:\n",
            "        1. Primarily use English in your responses, but adjust complexity based on the proficiency level\n",
            "        2. For beginners, use simple phrases and include translations to Odia in parentheses\n",
            "        3. For intermediate learners, use more complex sentences and only translate difficult phrases\n",
            "        4. For advanced learners, use natural speech with idioms and colloquialisms\n",
            "        5. Stay in character for the scene\n",
            "        6. If the user makes a language mistake, gently correct it and explain the correction\n",
            "        7. Keep responses concise and focused on the conversation\n",
            "        \n",
            "        User's message: Soro\n",
            "        \n",
            "        Your response in English (with appropriate help based on their level):\n",
            "        \u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Bot: \"Soro\" means straight, right? (ସୋର ଅର୍ଥ ସିଧା, ନା?)  So, I go straight? (ତେବେ ମୁଁ ସିଧା ଯିବି କି?)  For how long? (କେତେ ସମୟ ପାଇଁ?)  Is it far? (ଏହା ଦୂର କି?)  Can I walk there, or should I take a bus/taxi? (ମୁଁ ସେଠାକୁ ଚାଲିପାରିବି କି, ନା ବସ୍/ଟ୍ୟାକ୍ସି ନେବା ଉଚିତ?)\n",
            "\n",
            "You: exit\n",
            "\n",
            "Session complete! You made no mistakes in this session. Great job!\n"
          ]
        }
      ],
      "source": [
        "chatbot = LanguageLearningChatbot()\n",
        "chatbot.start_onboarding()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzYbfc0ynQT8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "lang_gpt",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
